---
title: "Functions for week 1"
author: "Catherine Forbes"
date: '2022-08-09'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, error = FALSE, message = FALSE, eval = TRUE, comment=NA, tidy=TRUE, tidy.opts = list(width.cutoff = 60))

library(tidyverse)
```

## Beta-Bernoulli (slide 27)

If $Y_1, Y_2,\ldots, Y_n \mid \theta \overset{i.i.d.}{\sim} Bernoulli(n,\theta)$, where $n$ is fixed and known (i.e. is non-random), and if $\theta \sim Beta(\alpha_0,\beta_0)$, where $\alpha_0>0$ and $\beta_0>0$ are non-random hyperparameters, then
$$\theta \mid y_1, y_2,\ldots, y_n \sim Beta(\alpha_1, \beta_1),$$ 
where 
\begin{align*}
\alpha_1 & = \alpha_0 + \sum_{i=1}^n y_i\\
\beta_1 & = \beta_0 + n - \sum_{i=1}^n y_i,
\end{align*}
where $y_1, y_2,\ldots, y_n$ denote the observed values of $Y_1, Y_2,\ldots, Y_n$, respectively. 


What does this mean? As a Bayesian, we put a prior distribution over the unknown value of $\theta$ (even though we know in this simulation that $p=0.8$....). In this case, since $\theta$ represents a probability which must lie within the unit interval, we choose a $Beta(\alpha_0, \beta_0)$ distribution. Then, using Bayes' theorem, we find that after conditioning on the observed data values, $\theta \mid y_1, y_2,\ldots, y_n$ will have a $Beta(\alpha_1, \beta_1)$ distribution, where $\alpha_1$ and $\beta_1$ are computed as detailed above. This $Beta(\alpha_1, \beta_1)$ distribution is the posterior distribution for this problem. Notice that when we start with $\theta \sim Beta$, 

The function below takes the data values $y_1, y_2,\ldots, y_n$, as well as the prior hyperparameters $\alpha_0$ and $\beta_0$, and returns the posterior hyperparameters $\alpha_1$ and $\beta_1$. 


```{r}

BetaBernoulli.f <- function(y = numeric(), a0, b0, 
pr = c(0.025, 0.05, 0.25, 0.5, 0.75, 0.95, 0.975), plot = FALSE){
  
  # would be good to make input values more robust
  
  # if(is.na(y) == TRUE){
  #   y <- numeric()
  # }

n <- length(y)

sumy <- sum(y)
a1 <- a0 + sumy # update first hyperparameter (shape 1)
b1 <- b0 + n - sumy # update second hyperparameter (shape 2)

############ we have found the posterior distribution above ############
############ now we want to output various properties of it ############

# posterior (updated) Beta distribution mean and variance
m <- a1/(a1 + b1) # mean
v <- a1*b1/(((a1 + b1)^2)*(a1 + b1 + 1)) # variance

# posterior (updated) Beta distribution quantiles 
nn <- length(pr)
q <- rep(NA, nn)
for(i in 1:nn){
  q[i] <- qbeta(pr[i], shape1 = a1, shape2 = b1)
}

out <- list(a1 = a1, b1 = b1, m = m, v = v, pr = pr, q = q, pdfplot = NA)

if(plot == TRUE){
# would be good to have some way to automate the y-limits on the plot
# perhaps check if end points are higher than the middle and restrict to the 
# lower of the two 
  
 xlims <- qbeta(c(0.001,0.999), shape1 = a1, shape2 = b1)
 xgrid <- seq(xlims[1], xlims[2], 0.001)
 
 betapdf <- dbeta(xgrid, shape1 = a1, shape2 = b1)
 dt <- tibble(theta = xgrid, pdf = betapdf)

 pdfplot <- dt %>% ggplot(aes(theta, pdf)) + 
  geom_line(colour = "blue") + 
  geom_hline(yintercept = 0) 
 out$pdfplot <- pdfplot
}

return(out)

}
```


Now let's try out the function by generating $n=10$ i.i.d. Bernoulli observations, with true probability of success $p=0.8$ (which we will be estimated as "$\theta$"). 

```{r}

set.seed(67869)
# set.seed(678691)

p <- 0.8 # true probability of success
n <- 10
y <- rbinom(n, size=1, prob=p)
y

```


What will our posterior distribution be?

```{r}
post <- BetaBernoulli.f(y = y, a0 = 0.5, b0 = 0.5, plot = TRUE)
post
```


# come back to this...

What will our posterior distribution be?

```{r}
post <- BetaBernoulli.f(y = numeric(), a0 = 0.5, b0 = 0.5, plot = TRUE)
post$pdfplot
```
# Let's apply this to the Georgia vote data

```{r}
library(faraway)
gavote <- as.tibble(gavote)

bushvotes <- c(rep(0, gavote$votes[1]))
bushvotes[1:gavote$bush[1]] <- 1

length(bushvotes)
sum(bushvotes)

post <- BetaBernoulli.f(y = numeric(), a0 = 10, b0 = 1, plot = TRUE)
post
```
# Maybe a smaller sample...

```{r}
library(faraway)
gavote <- as.tibble(gavote)

bushvotes <- c(rep(0, 100))

prop <- gavote$bush[1]/gavote$votes[1] # same proportion
bushcount <- floor(prop*100)
bushcount
bushvotes[1:bushcount] <- 1

length(bushvotes)
sum(bushvotes)

post <- BetaBernoulli.f(y = bushvotes, a0 = 10, b0 = 1, plot = TRUE)
post
```


```{r eval=FALSE}
postpdf <- dbeta(pgrid, shape1 = post$a1, shape2 = post$b1)
dt <- dt %>% mutate(postpdf = postpdf)

plotprior + 
  geom_line(aes(x=pgrid, y=postpdf), data = dt, colour = "darkviolet") +
  geom_point(aes(x=0.8,y=0), colour="red") +
  geom_segment(aes(x=.6,y=0, xend = .6, yend = 10), colour="cyan") +
  ggtitle("Prior pdf (blue), true proportion (green), sample proportion (cyan) and Posterior pdf (violet)") +
  theme(title =element_text(size=8))

```



